{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook produces the figure for the single cell related study in the main text for illustrating applications of our method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "prefix = \"test\"\n",
    "\n",
    "cell_type_selection = \"filter\"\n",
    "\n",
    "n_samples = 10\n",
    "sampling_scheme = \"double-replacement\"\n",
    "n_sampled_cells_per_celltype = 1000  # for top-k calculation\n",
    "\n",
    "topk_target = \"function\"  # phenotype or function\n",
    "topk_ratio = 0.001\n",
    "\n",
    "n_max_cells_emb = 100  # for visualization \n",
    "\n",
    "n_threads = 64\n",
    "n_jobs_topk = 64\n",
    "n_jobs_fcs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "\n",
    "# prefix = \"pheno_v1\"\n",
    "\n",
    "# cell_type_selection = \"filter\"\n",
    "\n",
    "# n_samples = 100\n",
    "# sampling_scheme = \"double-replacement\"\n",
    "# n_sampled_cells_per_celltype = 10000  # for top-k calculation\n",
    "# topk_target = \"phenotype\"  # 0.01%\n",
    "# topk_ratio = 0.0001  # 0.01%\n",
    "\n",
    "# n_max_cells_emb = 1000  # for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "\n",
    "# prefix = \"function300_v1\"\n",
    "\n",
    "# cell_type_selection = \"filter\"\n",
    "\n",
    "# n_samples = 300\n",
    "# sampling_scheme = \"double-replacement\"\n",
    "# n_sampled_cells_per_celltype = 10000  # for top-k calculation\n",
    "# topk_target = \"function\"  # 0.01%\n",
    "# topk_ratio = 0.0001  # 0.01%\n",
    "\n",
    "# n_max_cells_emb = 3000  # for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "prefix = \"function1000_v1\"\n",
    "\n",
    "cell_type_selection = \"filter\"\n",
    "\n",
    "n_samples = 1000\n",
    "sampling_scheme = \"double-replacement\"\n",
    "n_sampled_cells_per_celltype = 10000  # for top-k calculation\n",
    "topk_target = \"function\"  # 0.01%\n",
    "topk_ratio = 0.0001  # 0.01%\n",
    "\n",
    "n_max_cells_emb = 1000  # for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# prefix = \"rescue_v3\"\n",
    "# n_samples = 100\n",
    "# sampling_scheme = \"double-replacement\"\n",
    "# n_sampled_cells_per_celltype = 10000\n",
    "# topk_target = \"function\"\n",
    "# topk_ratio = 0.001\n",
    "# cell_type_selection = \"filter\"\n",
    "# n_max_cells_emb = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "\n",
    "# prefix = \"combined_v1\"\n",
    "\n",
    "# cell_type_selection = \"filter\"\n",
    "\n",
    "# n_samples = 100\n",
    "# sampling_scheme = \"double-replacement\"\n",
    "# n_sampled_cells_per_celltype = 10000  # for top-k calculation\n",
    "# topk_target = \"combined\"  # 0.01%\n",
    "# topk_ratio = 0.0001  # 0.01%\n",
    "\n",
    "# n_max_cells_emb = 1000  # for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_name = f\"application___singlecell\"\\\n",
    "                f\"___parameters\"\\\n",
    "                f\"___prefix__{prefix}\"\\\n",
    "                f\"___cell_types__{cell_type_selection}\"\\\n",
    "                f\"___n_samples__{n_samples}\"\\\n",
    "                f\"___sampling_scheme__{sampling_scheme}\"\\\n",
    "                f\"___n_sampled_cells_per_celltype__{n_sampled_cells_per_celltype}\"\\\n",
    "                f\"___topk_target__{topk_target}\"\\\n",
    "                f\"___topk_ratio__{topk_ratio}\"\\\n",
    "                f\"___n_max_cells_emb__{n_max_cells_emb}\"\n",
    "print(notebook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# disable parallelization for BLAS and co.\n",
    "from corals.threads import set_threads_for_external_libraries\n",
    "set_threads_for_external_libraries(n_threads=n_threads)\n",
    "\n",
    "# general\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import warnings \n",
    "import joblib\n",
    "import pathlib\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# ml / stats\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# init matplotlib defaults\n",
    "import matplotlib\n",
    "# matplotlib.rcParams['figure.facecolor'] = (1,1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "import sklearn.manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import corals.correlation.utils\n",
    "import sklearn.impute\n",
    "from coralsarticle.visualization import CurvedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from coralsarticle.data.process.singlecell import load_cytof, prepare_cell_sampling, sample_cell_subgroups\n",
    "import coralsarticle.data.process.singlecell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"../_out/\" + notebook_name)\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load essentials\n",
    "print(path)\n",
    "cell_types = pickle.load(open(path / \"cell_types.pickle\", \"rb\"))\n",
    "subgroups = pickle.load(open(path / \"subgroups.pickle\", \"rb\"))\n",
    "\n",
    "cells_phenotype_loaded = pickle.load(open(path / \"cells_phenotype.pickle\", \"rb\"))\n",
    "cells_function_loaded = pickle.load(open(path / \"cells_function.pickle\", \"rb\"))\n",
    "\n",
    "topk_loaded = pickle.load(open(path / \"topk.pickle\", \"rb\"))\n",
    "topk_matrices_loaded = pickle.load(open(path / \"topk_matrices.pickle\", \"rb\"))\n",
    "\n",
    "topk_stats_samples = pickle.load(open(path / \"topk_stats_samples.pickle\", \"rb\"))\n",
    "\n",
    "cells_phenotype_emb_loaded = pickle.load(open(path / \"cells_phenotype_emb.pickle\", \"rb\"))\n",
    "cells_phenotype_emb_idx_loaded = pickle.load(open(path / \"cells_phenotype_emb_idx.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# support legacy samples\n",
    "idx_deque = -1\n",
    "if isinstance(cells_phenotype_loaded, collections.deque):\n",
    "    cells_phenotype = cells_phenotype_loaded[idx_deque]\n",
    "    cells_function = cells_function_loaded[idx_deque]\n",
    "    topk = topk_loaded[idx_deque]\n",
    "    topk_matrices = topk_matrices_loaded[idx_deque]\n",
    "    cells_phenotype_emb = cells_phenotype_emb_loaded[idx_deque]\n",
    "    cells_phenotype_emb_idx = cells_phenotype_emb_idx_loaded[idx_deque]\n",
    "else:\n",
    "    # legacy samples\n",
    "    cells_phenotype = cells_phenotype_loaded\n",
    "    cells_function = cells_function_loaded\n",
    "    topk = topk_loaded\n",
    "    topk_matrices = topk_matrices_loaded\n",
    "    cells_phenotype_emb = cells_phenotype_emb_loaded\n",
    "    cells_phenotype_emb_idx = cells_phenotype_emb_idx_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_type_order = coralsarticle.data.process.singlecell.CELL_TYPE_ORDERS[cell_type_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Should load this from files (it is stored as `topk_stats_bins.pickle`)\n",
    "bins = np.concatenate([[-2], np.linspace(-1,1,201), [2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_keys = pd.read_excel(\"../data/raw/singlecell/cell_keys.xlsx\")\n",
    "rename = {r[\"Cell Key\"]:r[\"Short Name\"] for _, r in cell_keys.iterrows()}\n",
    "cell_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cell_keys[[\"Short Name\", \"Long Name\"]].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# n = len(cell_type_order)\n",
    "# fig, axes = plt.subplots(n, n, figsize=(4 * n, 4 * n))\n",
    "# for i1, c1 in enumerate(cell_type_order):\n",
    "#     for i2, c2 in enumerate(cell_type_order):\n",
    "#         pair = (c1, c2)\n",
    "#         ax = axes[i1, i2]\n",
    "#         skip = False\n",
    "#         for t in df.timepoint.unique():\n",
    "#             v = df.loc[df.timepoint == t][pair]\n",
    "#             if len(np.unique(v)) == 1:\n",
    "#                 skip =True\n",
    "        \n",
    "#         if not skip:\n",
    "#             sns.kdeplot(df[pair], hue=df.timepoint, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# n = len(cell_type_order)\n",
    "# fig, axes = plt.subplots(n, n, figsize=(4 * n, 4 * n))\n",
    "# for i1, c1 in enumerate(cell_type_order):\n",
    "#     for i2, c2 in enumerate(cell_type_order):\n",
    "        \n",
    "#         pair = (c1, c2)\n",
    "#         ax = axes[i1, i2]\n",
    "#         skip = False\n",
    "#         for t in df.timepoint.unique():\n",
    "#             v = df.loc[df.timepoint == t][pair]\n",
    "#             if len(np.unique(v)) == 1:\n",
    "#                 skip =True\n",
    "        \n",
    "#         if not skip:\n",
    "#             diff = df[df.timepoint == \"T3\"][pair].values - df[df.timepoint == \"PP\"][pair].values\n",
    "\n",
    "#             q_left = np.quantile(diff, 0.05)\n",
    "#             q_right = np.quantile(diff, 0.95)\n",
    "# #             q_left = np.quantile(diff, 0.01)\n",
    "# #             q_right = np.quantile(diff, 0.99)\n",
    "            \n",
    "#             if q_right < 0:\n",
    "#                 color = \"orange\"\n",
    "#             elif q_left > 0:\n",
    "#                 color = \"blue\"\n",
    "#             else:\n",
    "#                 color = \"grey\"\n",
    "            \n",
    "#             sns.kdeplot(\n",
    "#                 diff, \n",
    "#                 ax=ax, \n",
    "#                 color=color,\n",
    "#                 linewidth=1 if q_left < 0 and q_right > 0 else 5)\n",
    "#             ax.axvline(0, color=\"black\", linewidth=3)\n",
    "#             ax.axvline(q_left, linestyle=\"--\", color=color)\n",
    "#             ax.axvline(q_right, linestyle=\"--\", color=color)\n",
    "#             ax.set_title(f\"{c1.replace('cells', '')} / {c2.replace('cells', '')}\")\n",
    "#             if pair in differential_cell_pairs_effect_size_map:\n",
    "#                 ax.annotate(f\"es={differential_cell_pairs_effect_size_map[pair]:.02}f\", xy=(10,10), xycoords=\"axes points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def effect_size_original(x, y, quantile_left=0.05, quantile_right=0.95):\n",
    "def effect_size_original(x, y, quantile_left=0.05, quantile_right=0.95):\n",
    "\n",
    "    # effect size\n",
    "    difference = (x - y)\n",
    "#     average = np.mean(difference)\n",
    "    average = np.median(difference)\n",
    "    left = np.quantile(difference, quantile_left)\n",
    "    right = np.quantile(difference, quantile_right)\n",
    "\n",
    "    if right < 0:\n",
    "        effect_size = average / (average - right)\n",
    "    elif left > 0:\n",
    "        effect_size = average / (average - left)\n",
    "    else:\n",
    "        effect_size = np.nan\n",
    "\n",
    "    if (left > 0 and right > 0) or (left < 0 and right < 0):\n",
    "        return effect_size\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def effect_size_cohen(x, y, threshold=0.8):\n",
    "    # https://en.wikipedia.org/wiki/Effect_size#Cohen's_d\n",
    "    es = (np.mean(x) - np.mean(y)) / np.sqrt((np.std(x)**2 + np.std(y)**2) / 2)\n",
    "    return np.nan if threshold is not None and np.abs(es) < threshold else es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def effect_size_cohen_sample(x, y, threshold=1.2, quantile_left=0.05, quantile_right=0.95):  \n",
    "def effect_size_cohen_sample(x, y, threshold=1.2, quantile_left=0.05, quantile_right=0.95):  \n",
    "    \n",
    "    effect_sizes = []\n",
    "            \n",
    "    for i in range(100):\n",
    "        idx_x = np.random.choice(np.arange(len(x)), len(x), replace=True)\n",
    "        idx_y = np.random.choice(np.arange(len(y)), len(y), replace=True)\n",
    "        effect_size = effect_size_cohen(x[idx_x], y[idx_y], threshold=None)\n",
    "        effect_sizes.append(effect_size)\n",
    "\n",
    "    es_mean = np.mean(effect_sizes)\n",
    "    left = np.quantile(effect_sizes, quantile_left)  # two sided 0.025/0.975 threshold!? not sure\n",
    "    right = np.quantile(effect_sizes, quantile_right)\n",
    "\n",
    "#     plt.figure()\n",
    "#     sns.kdeplot(effect_sizes)\n",
    "#     plt.axvline(es_mean)\n",
    "#     plt.axvline(left)\n",
    "#     plt.axvline(right)\n",
    "#     plt.show()\n",
    "    \n",
    "    if np.abs(es_mean) >= threshold:\n",
    "        if (left > 0 and right > 0) or (left < 0 and right < 0):\n",
    "            return es_mean\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def effect_size_cohen_median(x, y, threshold=1.2):\n",
    "def effect_size_cohen_median(x, y, threshold=1.2):\n",
    "    # TODO: \n",
    "    # would be better to use PERCENTAGE BEND MIDVARIANCE probably: https://garstats.wordpress.com/2018/04/04/dbias/\n",
    "    # though still not good probably: https://aakinshin.net/posts/nonparametric-effect-size2/\n",
    "    # note: totally breaks down for non-normal it seems, with huuuuge median_abs_deviations\n",
    "    effect_size = (np.median(x) - np.median(y)) / np.sqrt((scipy.stats.median_abs_deviation(x)**2 + scipy.stats.median_abs_deviation(y)**2) / 2)\n",
    "    return np.nan if np.abs(effect_size) < threshold else effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_size_median_relative(x, y, threshold=0.5, quantile_left=0.05, quantile_right=0.95):\n",
    "    effect_sizes = []\n",
    "    effect_sizes_relative = []\n",
    "\n",
    "    for i in range(1000):\n",
    "        idx_x = np.random.choice(np.arange(len(x)), len(x), replace=True)\n",
    "        idx_y = np.random.choice(np.arange(len(y)), len(y), replace=True)\n",
    "\n",
    "        median_x = np.median(x[idx_x])\n",
    "        median_y = np.median(y[idx_y])\n",
    "\n",
    "        effect_size = median_x - median_y\n",
    "        effect_sizes.append(effect_size)\n",
    "\n",
    "        if median_x == 0 and median_y == 0:\n",
    "            effect_size_relative = 0\n",
    "        elif median_x == 0 or median_y == 0:\n",
    "            effect_size_relative = np.sign(median_x - median_y) * 10\n",
    "        else:\n",
    "            effect_size_relative =  np.sign(median_x - median_y) * (max(median_x, median_y) / min(median_x, median_y) - 1)           \n",
    "        effect_sizes_relative.append(effect_size_relative)\n",
    "\n",
    "    es_mean = np.mean(effect_sizes)\n",
    "    left = np.quantile(effect_sizes, quantile_left)\n",
    "    right = np.quantile(effect_sizes, quantile_right)\n",
    "\n",
    "    esr_median = np.median(effect_sizes_relative)\n",
    "\n",
    "    if np.abs(esr_median) >= 0.5:\n",
    "        if (left > 0 and right > 0) or (left < 0 and right < 0):\n",
    "            return esr_median\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliffs_delta_threshold = 0.622\n",
    "def effect_size_cliffs_delta(x, y, p_threshold=0.05, effect_size_threshold=0.622):\n",
    "    \"\"\"\n",
    "    With a large grain of salt, for interpretation we could convert Cohen's d thresholds defined by \n",
    "    \n",
    "    > Sawilowsky, S (2009). \"New effect size rules of thumb\" (Wikipedia)\n",
    "    \n",
    "    to Cliff's delta by assuming underlying normal distributions:\n",
    "    \n",
    "    > Appropriate statistics for ordinal level data: Should we really be using t-test and cohenâ€™s d for evaluating group differences on the NSSE and other surveys? 2006, Ramano et al.\n",
    "\n",
    "    For this we can for example use `cohd2delta` from R library `orddom`.\n",
    "\n",
    "    This results in:\n",
    "      * Very small cohen=0.01, cliffs=0.077\n",
    "      * Small      cohen=0.20, cliffs=0.147\n",
    "      * Medium     cohen=0.50, cliffs=0.330\n",
    "      * Large      cohen=0.80, cliffs=0.474\n",
    "      * -          cohen=1.00, cliffs=0.554\n",
    "      * Very large cohen=1.20, cliffs=0.622\n",
    "      * Huge       cohen=2.00, cliffs=0.811\n",
    "    \"\"\"\n",
    "    if x.size == 0 or y.size == 0:\n",
    "        warnings.warn(\"No data given for `x` or `y`.\")\n",
    "        return np.nan\n",
    "    u, p = scipy.stats.mannwhitneyu(x, y)\n",
    "    es = cliffsDelta(x, y)\n",
    "    \n",
    "    if p_threshold is not None and p > p_threshold:\n",
    "        return np.nan\n",
    "    if effect_size_threshold is not None and abs(es) < effect_size_threshold:\n",
    "        return np.nan\n",
    "    return es\n",
    "    \n",
    "# the following code is based on: https://github.com/neilernst/cliffsDelta/blob/master/cliffsDelta.py\n",
    "\n",
    "def cliffsDelta(lst1, lst2):\n",
    "\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    return d\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate statistically significant differences\n",
    "\n",
    "sample = []\n",
    "timepoint = []\n",
    "matrices = []\n",
    "for i_sample, stats in enumerate(topk_stats_samples):\n",
    "    for k,v in stats.items():\n",
    "        sample.append(i_sample)\n",
    "        timepoint.append(k)\n",
    "        matrices.append(v[\"counts\"].reshape(1, -1))\n",
    "#         matrices.append(v[\"means\"].reshape(1, -1))\n",
    "matrices = np.concatenate(matrices)\n",
    "    \n",
    "cc = [(c1,c2) for c1 in cell_types for c2 in cell_types]\n",
    "df = pd.DataFrame(matrices, columns=cc)\n",
    "df.insert(0, \"sample\", sample)\n",
    "df.insert(1, \"timepoint\", timepoint)\n",
    "\n",
    "differential_cell_pairs = []\n",
    "differential_cell_pairs_p = []\n",
    "\n",
    "differential_cell_pairs_effect_size = []\n",
    "differential_cell_pairs_effect_size_stats = []\n",
    "\n",
    "for c in cc:\n",
    "    msk_x = df[\"timepoint\"] == \"T3\"\n",
    "    msk_y = df[\"timepoint\"] == \"PP\"\n",
    "    \n",
    "    x = df.loc[msk_x,[c]].values.flatten()\n",
    "    y = df.loc[msk_y,[c]].values.flatten()\n",
    "    \n",
    "    if not np.all((y - x) == 0):\n",
    "#         print(c, x, y)\n",
    "\n",
    "        # p-value\n",
    "        w,p = scipy.stats.ranksums(x,y)\n",
    "        if p < 0.05 / cell_type_order.size**2:\n",
    "            differential_cell_pairs.append(c)\n",
    "            differential_cell_pairs_p.append(p)\n",
    "\n",
    "#         effect_size_mode = \"original\"\n",
    "#         effect_size_mode = \"cohen\"\n",
    "#         effect_size_mode = \"cohen_median\"\n",
    "#         effect_size_mode = \"cohen_sample\"\n",
    "#         effect_size_mode = \"median_relative\"\n",
    "        effect_size_mode = \"cliffs_delta\"\n",
    "            \n",
    "        if effect_size_mode == \"original\":\n",
    "            effect_size = effect_size_original(x, y)\n",
    "\n",
    "        elif effect_size_mode == \"median_relative\":\n",
    "            effect_size = effect_size_median_relative(x, y)\n",
    "            \n",
    "        elif effect_size_mode == \"cohen\":\n",
    "            effect_size = effect_size_cohen(x, y)\n",
    "                \n",
    "        elif effect_size_mode == \"cohen_sample\":\n",
    "            effect_size = effect_size_cohen_sample(x, y)\n",
    "            \n",
    "        elif effect_size_mode == \"cohen_median\":\n",
    "            effect_size = effect_size_cohen_median(x, y)\n",
    "            \n",
    "        elif effect_size_mode == \"cliffs_delta\":\n",
    "            effect_size = effect_size_cliffs_delta(x, y, p_threshold=0.05, effect_size_threshold=cliffs_delta_threshold)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown effect size mode: {effect_size_mode}\")\n",
    "            \n",
    "        if not np.isnan(effect_size):  \n",
    "            differential_cell_pairs_effect_size.append(c)\n",
    "            differential_cell_pairs_effect_size_stats.append(effect_size)\n",
    "\n",
    "differential_cell_pairs_map = {\n",
    "    k:p for k,p in zip(differential_cell_pairs, differential_cell_pairs_p)}\n",
    "\n",
    "differential_cell_pairs_effect_size_map = {\n",
    "    k:p for k,p in zip(differential_cell_pairs_effect_size, differential_cell_pairs_effect_size_stats) \n",
    "}\n",
    "\n",
    "print(len(differential_cell_pairs_map))\n",
    "print(len(differential_cell_pairs_effect_size_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"mDCs_noMDSC\", \"ncMCs_noMDSC\") in cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "n = len(cell_type_order)\n",
    "fig, axes = plt.subplots(n, n, figsize=(4 * n, 4 * n))\n",
    "\n",
    "for i1, c1 in enumerate(cell_type_order):\n",
    "    for i2, c2 in enumerate(cell_type_order):\n",
    "        \n",
    "        pair = (c1, c2)\n",
    "        ax = axes[i1, i2]\n",
    "        skip = False\n",
    "        for t in df.timepoint.unique():\n",
    "            v = df.loc[df.timepoint == t][pair]\n",
    "            if len(np.unique(v)) == 1:\n",
    "                skip =True\n",
    "        \n",
    "        if not skip:\n",
    "            sns.kdeplot(\n",
    "                df[pair], \n",
    "                hue=df.timepoint, \n",
    "                ax=ax, \n",
    "                linewidth=5 if (c1,c2) in differential_cell_pairs_effect_size_map or (c2,c1) in differential_cell_pairs_effect_size_map else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# pair = (\"mDCs_noMDSC\", \"ncMCs_noMDSC\")\n",
    "pair = (\"Bcells\", \"CD16+CD56-NKcells\")\n",
    "# pair = list(differential_cell_pairs_effect_size_map.keys())[0]\n",
    "\n",
    "v1 = df.loc[df.timepoint == \"T3\"][pair].values\n",
    "v2 = df.loc[df.timepoint == \"PP\"][pair].values\n",
    "es = effect_size_cohen_median(v1, v2)\n",
    "es = effect_size_cliffs_delta(v1, v2)\n",
    "print(\n",
    "    es, \n",
    "    differential_cell_pairs_effect_size_map[pair] if pair in differential_cell_pairs_effect_size_map or (pair[1],pair[0]) in differential_cell_pairs_effect_size_map else \"NA\",\n",
    "    scipy.stats.shapiro(v1)[1],\n",
    "    scipy.stats.shapiro(v2)[1]\n",
    "    )\n",
    "\n",
    "sns.kdeplot(df[pair], hue=df.timepoint, linewidth=5 if (pair[1],pair[0]) in differential_cell_pairs_effect_size_map or pair in differential_cell_pairs_effect_size_map else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import corals.correlation.fast\n",
    "\n",
    "# a = cells_function[\"T3\"][pair[0]]\n",
    "# b = cells_function[\"T3\"][pair[1]]\n",
    "# c1 = corals.correlation.fast.cor_matrix_symmetrical(a.transpose(), b.transpose())\n",
    "# c1 = c1[c1 > 0.8]\n",
    "\n",
    "# a = cells_function[\"PP\"][pair[0]]\n",
    "# b = cells_function[\"PP\"][pair[1]]\n",
    "# c2 = corals.correlation.fast.cor_matrix_symmetrical(a.transpose(), b.transpose())\n",
    "# c2 = c2[c2 > 0.8]\n",
    "\n",
    "# sns.histplot(x=np.concatenate([c1.flatten(), c2.flatten()]), hue=np.repeat([\"T3\", \"PP\"], (c1.size, c2.size)))\n",
    "# # plt.xlim((-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types_innate = cell_type_order[2:7]\n",
    "cell_types_adaptive = cell_type_order[9:]\n",
    "print(cell_type_order)\n",
    "print(cell_types_innate)\n",
    "print(cell_types_adaptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_figures = pathlib.Path(f\"../_out/figures/{notebook_name}\")\n",
    "path_figures.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_colors = [sns.color_palette('deep')[1],sns.color_palette()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# source: https://stackoverflow.com/questions/67188162/is-there-a-way-to-add-hatch-marks-on-a-seaborn-displot-using-a-kernal-density-es\n",
    "\n",
    "bcells_label = cell_keys.set_index('Cell Key').loc['Bcells', 'Short Name']\n",
    "nkcells_label = cell_keys.set_index('Cell Key').loc['CD16+CD56-NKcells', 'Short Name']\n",
    "plots = [\n",
    "        (f\"innate / {bcells_label}\", \"Bcells\", cell_types_innate),\n",
    "        (f\"innate / {nkcells_label}\", \"CD16+CD56-NKcells\", cell_types_innate),\n",
    "        (f\"adaptive / {bcells_label}\", \"Bcells\", cell_types_adaptive),\n",
    "        (f\"adaptive / {nkcells_label}\", \"CD16+CD56-NKcells\", cell_types_adaptive)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(4.2, 2* 4), sharex=False, sharey=False, dpi=300)\n",
    "\n",
    "for i, (name, source, targets) in enumerate(plots):\n",
    "\n",
    "    ax = axes[i]\n",
    "\n",
    "    v1 = np.array([df.loc[df.timepoint == \"T3\"][(source, t)].values for t in targets]).sum(axis=0)\n",
    "    v2 = np.array([df.loc[df.timepoint == \"PP\"][(source, t)].values for t in targets]).sum(axis=0)\n",
    "\n",
    "    # es = effect_size_cohen_median(v1, v2)\n",
    "    es = effect_size_cliffs_delta(v1, v2, None, None)\n",
    "    print(es)\n",
    "    # print(\n",
    "    #     es, \n",
    "    #     differential_cell_pairs_effect_size_map[pair] if pair in differential_cell_pairs_effect_size_map or (pair[1],pair[0]) in differential_cell_pairs_effect_size_map else \"NA\",\n",
    "    #     scipy.stats.shapiro(v1)[1],\n",
    "    #     scipy.stats.shapiro(v2)[1]\n",
    "    #     )\n",
    "\n",
    "    pal1 = [\"grey\", contrast_colors[0]]\n",
    "    pal2 = [\"grey\", contrast_colors[1]]\n",
    "    if es > 0:\n",
    "        pal = pal2\n",
    "    else:\n",
    "        pal = pal1\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        x=v2, \n",
    "        fill=True, common_norm=False, palette=pal,\n",
    "        alpha=.8, linewidth=1,\n",
    "        color=pal[1],\n",
    "        label=\"PP\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        x=v1, \n",
    "        fill=True, common_norm=False, palette=pal,\n",
    "        alpha=.3, linewidth=1,\n",
    "        color=pal[1],\n",
    "        label=\"T3\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    \n",
    "    hatches = ['///', '']\n",
    "    for collection, hatch in zip(ax.collections[::-1], hatches):\n",
    "        collection.set_hatch(hatch)\n",
    "    \n",
    "    ax.legend(facecolor=(1,1,1,0.3), fancybox=False, edgecolor='None', loc=\"lower right\", borderaxespad=0.08)\n",
    "    \n",
    "#     ax.set_axis_off()\n",
    "#     ax.legend().remove()\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    ax.set_xticklabels([f\"{t / 1000:.0f}\" for t in ax.get_xticks()])\n",
    "    ax.annotate(name, (0,.075), xycoords=\"axes fraction\", bbox=dict(facecolor='white', edgecolor='None', alpha=0.3))\n",
    "\n",
    "    # sns.violinplot(\n",
    "    #     y=np.concatenate([v1, v2]), \n",
    "    #     x=np.repeat([\"T3\", \"PP\"], (v1.size, v2.size)))\n",
    "    if i + 1 == len(plots):\n",
    "        ax.set_xlabel(\"number of top-k correlation ($10^3$)\")\n",
    "\n",
    "fig.savefig(path_figures / \"innate_adaptive.pdf\", bbox_inches=\"tight\", facecolor='none') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting necessary libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# # we generate a color palette with Seaborn.color_palette()\n",
    "# pal = sns.color_palette(palette='coolwarm', n_colors=12)\n",
    "\n",
    "\n",
    "# # in the sns.FacetGrid class, the 'hue' argument is the one that is the one that will be represented by colors with 'palette'\n",
    "# g = sns.FacetGrid(\n",
    "#     pd.DataFrame(dict(count=np.concatenate([v1, v2]), row=np.repeat([\"T3\", \"PP\"], (v1.size, v2.size)))), \n",
    "#     row=\"row\", \n",
    "#     hue=\"row\", \n",
    "#     aspect=5, \n",
    "#     height=3, \n",
    "#     palette=pal)\n",
    "\n",
    "# # then we add the densities kdeplots for each month\n",
    "# g.map(sns.kdeplot, 'count',\n",
    "#       bw_adjust=1, clip_on=False,\n",
    "#       fill=True, alpha=1, linewidth=1.5)\n",
    "\n",
    "# # here we add a white line that represents the contour of each kdeplot\n",
    "# g.map(sns.kdeplot, 'count', \n",
    "#       bw_adjust=1, clip_on=False, \n",
    "#       color=\"w\", lw=2)\n",
    "\n",
    "# # here we add a horizontal line for each plot\n",
    "# g.map(plt.axhline, y=0,\n",
    "#       lw=2, clip_on=False)\n",
    "\n",
    "# # # we loop over the FacetGrid figure axes (g.axes.flat) and add the month as text with the right color\n",
    "# # # notice how ax.lines[-1].get_color() enables you to access the last line's color in each matplotlib.Axes\n",
    "# # for i, ax in enumerate(g.axes.flat):\n",
    "# #     ax.text(-15, 0.02, month_dict[i+1],\n",
    "# #             fontweight='bold', fontsize=15,\n",
    "# #             color=ax.lines[-1].get_color())\n",
    "    \n",
    "# # we use matplotlib.Figure.subplots_adjust() function to get the subplots to overlap\n",
    "# g.fig.subplots_adjust(hspace=-0.3)\n",
    "\n",
    "# # # eventually we remove axes titles, yticks and spines\n",
    "# g.set_titles(\"\")\n",
    "# g.set(yticks=[])\n",
    "# g.despine(bottom=True, left=True)\n",
    "\n",
    "# plt.setp(ax.get_xticklabels(), fontsize=15, fontweight='bold')\n",
    "# # plt.xlabel('Temperature in degree Celsius', fontweight='bold', fontsize=15)\n",
    "# # g.fig.suptitle('Daily average temperature in Seattle per month',\n",
    "# #                ha='right',\n",
    "# #                fontsize=20,\n",
    "# #                fontweight=20)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df.groupby(\"timepoint\").mean().drop(columns=\"sample\")\n",
    "mean_diff = mean.loc[\"T3\",:] - mean.loc[\"PP\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grouped = mean.copy()\n",
    "mean_grouped.columns = pd.MultiIndex.from_tuples(mean.columns)\n",
    "mean_grouped = mean_grouped.stack().groupby(\"timepoint\").sum()\n",
    "mean_grouped = mean_grouped.div(mean_grouped.max(axis=1).values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = df.groupby(\"timepoint\").std(ddof=0).drop(columns=\"sample\")\n",
    "std_diff = np.sqrt((std.loc[\"T3\",:]**2 + std.loc[\"PP\",:]**2) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size_matrix = mean_diff.div(std_diff)\n",
    "effect_size_matrix.index = pd.MultiIndex.from_tuples(effect_size_matrix.index)\n",
    "effect_size_matrix= effect_size_matrix.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(effect_size_matrix) >= 1.2).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17; tp=\"T3\"\n",
    "df.iloc[(df[\"timepoint\"] == \"T3\").values,i].hist(alpha=0.5)\n",
    "df.iloc[(df[\"timepoint\"] == \"PP\").values,i].hist(alpha=0.5)\n",
    "print(scipy.stats.shapiro(df.iloc[(df[\"timepoint\"] == \"T3\").values,i]))\n",
    "print(scipy.stats.shapiro(df.iloc[(df[\"timepoint\"] == \"PP\").values,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.ones((len(cell_type_order), len(cell_type_order)))\n",
    "for i1, c1 in enumerate(cell_type_order):\n",
    "    for i2, c2 in enumerate(cell_type_order):\n",
    "        if (c1, c2) in differential_cell_pairs_effect_size_map:\n",
    "            msk[i1,i2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.nanmax(np.abs(effect_size_matrix.values))\n",
    "m = effect_size_matrix.loc[cell_type_order, cell_type_order]\n",
    "sns.heatmap(\n",
    "    m, \n",
    "    center=0, vmin=-max_value, vmax=max_value, \n",
    "    mask=msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.nanmax(np.abs(effect_size_matrix.values))\n",
    "m = effect_size_matrix.loc[cell_type_order, cell_type_order]\n",
    "m[np.isnan(m)] = 0\n",
    "sns.clustermap(\n",
    "    m, \n",
    "    center=0, vmin=-max_value, vmax=max_value, \n",
    "    mask=msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# pair = (\"Bcells\", \"Bcells\")\n",
    "pair = (\"Bcells\", \"CD16+CD56-NKcells\")\n",
    "sns.kdeplot(df[pair], hue=df.timepoint)\n",
    "\n",
    "plt.figure()\n",
    "diff = df[df.timepoint == \"T3\"][pair].values - df[df.timepoint == \"PP\"][pair].values\n",
    "sns.kdeplot(diff, linewidth=1)\n",
    "plt.axvline(0, color=\"black\")\n",
    "plt.axvline(np.quantile(diff, 0.01), linestyle=\"--\", color=\"red\")\n",
    "plt.axvline(np.quantile(diff, 0.99), linestyle=\"--\", color=\"red\")\n",
    "plt.axvline(np.quantile(diff, 0.05), linestyle=\"--\")\n",
    "plt.axvline(np.quantile(diff, 0.95), linestyle=\"--\")\n",
    "plt.axvline(np.quantile(diff, 0.10), linestyle=\"--\", color=\"green\")\n",
    "plt.axvline(np.quantile(diff, 0.90), linestyle=\"--\", color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,v in differential_cell_pairs_effect_size_map.items():\n",
    "    print(c, v, mean_diff[c], mean[c])\n",
    "    print()\n",
    "\n",
    "    n_bins = 10\n",
    "    \n",
    "    sample = -2\n",
    "    i, j = np.argwhere(cell_types == c[0]).squeeze(), np.argwhere(cell_types == c[1]).squeeze()\n",
    "    if np.sum(topk_stats_samples[-1][\"T3\"][\"histograms\"][i,j][-n_bins:]) == 0:\n",
    "        i, j = j, i\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2,figsize=(8,4), sharey=True)\n",
    "\n",
    "    values_t3 = topk_stats_samples[sample][\"T3\"][\"histograms\"][i,j][-n_bins:]\n",
    "    values_pp = topk_stats_samples[sample][\"PP\"][\"histograms\"][i,j][-n_bins:]\n",
    "    \n",
    "    if np.sign(sum(values_t3) - sum(values_pp)) == np.sign(mean_diff[c]):\n",
    "        color = \"blue\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.bar(bins[:-1][-n_bins:], values_t3, width=0.01, color=color)\n",
    "    ax.set_title(f\"T3: {values_t3.sum()}\")\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.bar(bins[:-1][-n_bins:], values_pp, width=0.01, color=color)\n",
    "    ax.set_title(f\"PP: {values_pp.sum()}\")\n",
    "    fig.suptitle(f\"{cell_types[i]} / {cell_types[j]}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette(\"Spectral\", n_colors=32)\n",
    "color_palette = sns.diverging_palette(145, 300, s=60, n=32)\n",
    "neutral = [(.7,.7,.7)]\n",
    "color_palette = neutral * 2 + color_palette[0:6] + neutral + color_palette[-11:]\n",
    "sns.palplot(color_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_palette = sns.color_palette(\"deep\", n_colors=26)\n",
    "# sns.palplot(color_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive circle coordinates\n",
    "import math\n",
    "\n",
    "circle_coordinates = [(0,0)]\n",
    "circle_coordinates = []\n",
    "\n",
    "n = len(cell_type_order) - len(circle_coordinates)\n",
    "\n",
    "for i in range(n):    \n",
    "    x = math.cos(2 * math.pi * i / n)\n",
    "    y = math.sin(2 * math.pi * i / n)\n",
    "    circle_coordinates.append((x,y))\n",
    "circle_coordinates = np.stack(circle_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive cell coordinates\n",
    "cell_coordinates = dict()\n",
    "for i_cell_type, cell_type in enumerate(cell_type_order):\n",
    "\n",
    "    cell_type_subgroup_sizes = [cells_phenotype_emb[s][cell_type].shape[0] for s in subgroups]\n",
    "    cell_type_coordinates = np.concatenate([cells_phenotype_emb[s][cell_type] for s in subgroups])\n",
    "    cell_type_coordinates = sklearn.preprocessing.MinMaxScaler(feature_range=(-1,1)).fit_transform(cell_type_coordinates) / 10\n",
    "    cell_type_coordinates += circle_coordinates[i_cell_type]\n",
    "    \n",
    "    offset = 0\n",
    "    for i_subgroup, s in enumerate(subgroups):\n",
    "        end = offset + cell_type_subgroup_sizes[i_subgroup]\n",
    "        cell_coordinates.setdefault(s, dict())[cell_type] = cell_type_coordinates[offset:end,:]\n",
    "        offset = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transparent background\n",
    "# matplotlib.rcParams['figure.facecolor'] = 'white'\n",
    "# matplotlib.rcParams['figure.facecolor'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.pipeline\n",
    "\n",
    "def get_cell_colors(marker_category=\"function\", marker=0, color_map=\"inferno\"):\n",
    "    \n",
    "    if marker_category == \"pheno\":\n",
    "        cells = cells_phenotype\n",
    "    elif marker_category == \"function\":\n",
    "        cells = cells_function\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown marker category: {marker_category}\")\n",
    "        \n",
    "    if isinstance(color_map, str):\n",
    "        color_map = matplotlib.cm.get_cmap(color_map)\n",
    "\n",
    "    # calculate min/max\n",
    "    marker_values = np.concatenate([\n",
    "        cells[subgroup][cell_type][:,marker].flatten() \n",
    "        for subgroup in cells.keys()\n",
    "        for cell_type in cells[subgroup].keys()])\n",
    "    min_value, max_value = marker_values.min(), marker_values.max()\n",
    "    norm = sklearn.pipeline.make_pipeline(\n",
    "            sklearn.preprocessing.MinMaxScaler())\\\n",
    "        .fit(marker_values.reshape(-1,1))\n",
    "        \n",
    "    colors = {}\n",
    "    for cell_type in cell_type_order:\n",
    "        \n",
    "#         # calculate min/max\n",
    "#         marker_values = np.concatenate([\n",
    "#             cells[subgroup][cell_type][:,marker].flatten() \n",
    "#             for subgroup in cells.keys()])\n",
    "#         min_value, max_value = marker_values.min(), marker_values.max()\n",
    "#         norm = sklearn.pipeline.make_pipeline(\n",
    "#                 sklearn.preprocessing.MinMaxScaler())\\\n",
    "#             .fit(marker_values.reshape(-1,1))\n",
    "# #         norm = matplotlib.colors.Normalize(vmin=min_value, vmax=max_value)\n",
    "        \n",
    "        for s in subgroups:\n",
    "            marker_values = cells[s][cell_type][cells_phenotype_emb_idx[s][cell_type],marker].flatten()\n",
    "            cell_colors = color_map(norm.transform(marker_values.reshape(-1,1)).flatten())\n",
    "            colors.setdefault(s, {}).setdefault(cell_type, cell_colors)\n",
    "            \n",
    "    return colors\n",
    "\n",
    "cell_colors = get_cell_colors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.path import Path\n",
    "import matplotlib\n",
    "\n",
    "def plot_cells(subgroup, ax=None, title=None, cell_colors=\"grey\"):\n",
    "\n",
    "    # nodes\n",
    "    for i_order, cell_type in enumerate(cell_type_order):\n",
    "\n",
    "        emb = cell_coordinates[subgroup][cell_type]\n",
    "        \n",
    "        if isinstance(cell_colors, str):\n",
    "            colors = cell_colors\n",
    "            \n",
    "        elif isinstance(cell_colors, list):\n",
    "            colors = np.array([cell_colors[i_order]])\n",
    "            \n",
    "        elif isinstance(cell_colors, dict):\n",
    "            colors = cell_colors[subgroup][cell_type_order[i_order]]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError()\n",
    "            \n",
    "#         ax.scatter(emb[:,0], emb[:,1], s=1, zorder=-100, color=colors, alpha=0.8, linewidths=0)\n",
    "        ax.scatter(emb[:,0], emb[:,1], s=3, zorder=100, color=colors, alpha=0.99, linewidths=0)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circle(sizes, cell_colors=None, ax=None, divider_with=0.5, divider_thickness=None, thickness=5, radius=1):\n",
    "    \n",
    "    if divider_thickness is None:\n",
    "        divider_thickness = thickness\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    sizes_freq = sizes / np.max(sizes)\n",
    "    \n",
    "    segment_angle = 360 / len(sizes)\n",
    "    offset = 0#- segment_angle / 2\n",
    "    for i,s in enumerate(sizes_freq):\n",
    "        \n",
    "        start = offset -  segment_angle * s / 2 \n",
    "        end = offset\n",
    "        \n",
    "        if s > 0:\n",
    "            a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, theta1=offset-divider_with*0.5,theta2=offset+divider_with*0.5, linewidth=thickness, color=\"dimgrey\")\n",
    "            ax.add_patch(a1)\n",
    "\n",
    "            a2 = matplotlib.patches.Arc((0,0), radius*2, radius*2, theta1=start, theta2=end, linewidth=thickness,color=cell_colors[i])\n",
    "            ax.add_patch(a2)\n",
    "        \n",
    "        offset+= segment_angle\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circle_size(cell_colors=None, ax=None, divider_with=0.5, divider_thickness=None, thickness=5, radius=1, subgroup_include=None):\n",
    "    \n",
    "    sizes = np.array([\n",
    "        np.sum([\n",
    "            cells_phenotype[s][cell_type].shape[0] \n",
    "            for s in subgroups\n",
    "            if (subgroup_include is None or subgroup_include(s))]) \n",
    "        for cell_type in cell_type_order])\n",
    "     \n",
    "    plot_circle(sizes, cell_colors=cell_colors, ax=ax, divider_with=divider_with, divider_thickness=divider_thickness, thickness=thickness, radius=radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circle_n_edges(subgroup, cell_colors=None, ax=None, divider_with=0.5, divider_thickness=None, thickness=5, radius=1):\n",
    "    sizes= mean_grouped.loc[subgroup, cell_type_order].values\n",
    "    plot_circle(sizes, cell_colors=cell_colors, ax=ax, divider_with=divider_with, divider_thickness=divider_thickness, thickness=thickness, radius=radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circle_intra_edges(subgroup, cell_colors=None, ax=None, divider_with=0.5, divider_thickness=None, thickness=5, radius=1):\n",
    "    sizes = np.array([mean.loc[subgroup,:][(c,c)] if (c,c) in differential_cell_pairs_effect_size_map else 0 for c in cell_type_order])    \n",
    "    print(sizes)\n",
    "    plot_circle(sizes, cell_colors=cell_colors, ax=ax, divider_with=divider_with, divider_thickness=divider_thickness, thickness=thickness, radius=radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels(subgroup, ax=None, title=None, cell_colors=None, divider_with=0.5, divider_thickness=None, thickness=5, radius=1, stagger=None, rename=None):\n",
    "   \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(24,24))\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "\n",
    "#     # nodes\n",
    "    for i_order, cell_type in enumerate(cell_type_order):\n",
    "\n",
    "        emb = cell_coordinates[subgroup][cell_type]\n",
    "        \n",
    "        # label coordinates\n",
    "        label_coordinates = np.mean(emb, axis=0) * radius\n",
    "\n",
    "#         ax.text(*label_coordinates, cell_type, zorder=101)\n",
    "\n",
    "    sizes = np.array([1 for c in cell_type_order])\n",
    "    sizes_freq = sizes / np.max(sizes)\n",
    "    \n",
    "    segment_angle = 2 * np.pi / len(sizes)\n",
    "    offset = 0 * np.pi\n",
    "    for i,s in enumerate(sizes_freq):\n",
    "        \n",
    "        x = np.cos(offset) * radius\n",
    "        y =- np.sin(offset) * radius\n",
    "\n",
    "#         ax.text(x,y, \"blubb\")\n",
    "#         ax.scatter([x], [y], marker=\"x\")\n",
    "        \n",
    "        text = cell_type_order[i] if rename is None else rename[cell_type_order[i]]\n",
    "        \n",
    "        xx = np.cos(np.linspace(offset - (len(text) / 2 * 0.025), offset + segment_angle * 2, 100)) * radius\n",
    "        yy = -np.sin(np.linspace(offset - (len(text) / 2 * 0.025), offset + segment_angle * 2, 100)) * radius\n",
    "#         xx = np.cos(np.linspace(offset, offset + segment_angle * 2, 100)) * radius\n",
    "#         yy = -np.sin(np.linspace(offset, offset + segment_angle * 2, 100)) * radius\n",
    "        \n",
    "#         ax.scatter([x], [y])\n",
    "    \n",
    "        if stagger:\n",
    "            stagger_freq, stagger_offset = stagger\n",
    "            stagger_step = i % stagger_freq\n",
    "            xx *= 1 + (stagger_step * stagger_offset)\n",
    "            yy *= 1 + (stagger_step * stagger_offset) \n",
    "        \n",
    "        text = CurvedText(\n",
    "            x = xx,\n",
    "            y = yy,\n",
    "            text=text,\n",
    "            va = 'bottom',\n",
    "            ha=\"center\",\n",
    "            axes = ax, ##calls ax.add_artist in __init__\n",
    "            color=cell_colors[2], #cell_colors[i],\n",
    "#             weight=\"bold\",\n",
    "            fontsize=13\n",
    "        )\n",
    "        \n",
    "#         ax.text(x,y, text, zorder=101, va=\"center\", ha=\"center\", rotation=-offset / (2*np.pi) * 360 + 270)\n",
    "#         ax.scatter([0], [0])\n",
    "#         ax.scatter([x], [y])\n",
    "        \n",
    "        offset-= segment_angle\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary_circle_intracell(ax=None, colors=[\"red\", \"blue\"], divider_with=0.5, divider_thickness=None, thickness=5, radius=1, stagger=None):\n",
    "    \n",
    "    if divider_thickness is None:\n",
    "        divider_thickness = thickness\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    effect_size = np.array([\n",
    "        differential_cell_pairs_effect_size_map[(c,c)] \n",
    "        if (c,c) in differential_cell_pairs_effect_size_map else 0 \n",
    "        for c in cell_type_order])\n",
    "    \n",
    "    if sum(effect_size) == 0: return\n",
    "    \n",
    "    max_effect_size = max(np.abs(effect_size))\n",
    "    \n",
    "#     ax.bar(np.arange(sizes_freq.size), sizes_freq)\n",
    "    \n",
    "    bar_sizes = np.abs(effect_size / max_effect_size)\n",
    "    \n",
    "    segment_angle = 360 / len(bar_sizes)\n",
    "#     offset = - segment_angle / 2\n",
    "    offset = 0\n",
    "    for i, s in enumerate(bar_sizes):\n",
    "        \n",
    "        start = offset - segment_angle * s / 2\n",
    "        end = offset\n",
    "        \n",
    "        weight = mean_diff[(cell_type_order[i], cell_type_order[i])] # for direction (more or less)\n",
    "        edgecolors = colors[0] if weight < 0 else colors[1]\n",
    "        \n",
    "        # arc\n",
    "        if stagger:\n",
    "            stagger_freq, stagger_offset = stagger\n",
    "            stagger_step = i % stagger_freq\n",
    "            rr = radius * (1 + (stagger_step * stagger_offset))\n",
    "        else:\n",
    "            rr = radius\n",
    "        \n",
    "        a1 = matplotlib.patches.Arc((0,0), rr*2, rr*2, theta1=start,theta2=end, linewidth=thickness,color=edgecolors, alpha=0.7)\n",
    "        ax.add_patch(a1)\n",
    "        \n",
    "#         extend = 0.3\n",
    "#         ax.plot(\n",
    "#             [circle_coordinates[i][0] * (1 + 0.12), circle_coordinates[i][0] * (1 + extend)], \n",
    "#             [circle_coordinates[i][1] * (1 + 0.12), circle_coordinates[i][1] * (1 + extend)])\n",
    "#         ax.text(circle_coordinates[i][0] + (1 + 0.12), circle_coordinates[i][1] + (1 + 0.12), str(i))\n",
    "\n",
    "#         if s > 0:   \n",
    "#             diff = segment_angle * 1 / max_effect_size / 2\n",
    "#             start_ref = offset - diff\n",
    "#             end_ref = offset\n",
    "#             a3 = matplotlib.patches.Arc((0,0), radius*2, radius*2, theta1=start_ref,theta2=end_ref, linewidth=thickness,color=\"white\", alpha=0.8)\n",
    "#             ax.add_patch(a3)\n",
    "        \n",
    "        offset+= segment_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.path import Path\n",
    "\n",
    "def plot_summary(s, colors=[\"red\", \"blue\"], edges_kwargs=None, cell_type_pair_include=None, ax=None, linewidth_scaling=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.axis(\"off\")\n",
    "  \n",
    "    # edges\n",
    "    for i_order, cell_type_i in enumerate(cell_type_order):\n",
    "        \n",
    "        for j_order, cell_type_j in enumerate(cell_type_order):\n",
    "            \n",
    "            if (cell_type_pair_include is not None) and (not cell_type_pair_include(cell_type_i, cell_type_j)):\n",
    "                continue\n",
    "            \n",
    "            i = np.argwhere(cell_types == cell_type_i).squeeze()\n",
    "            j = np.argwhere(cell_types == cell_type_j).squeeze()\n",
    "            \n",
    "            if i_order < j_order:\n",
    "#                 print(cell_type_i, cell_type_j)\n",
    "#                 i_start = sum([cells_phenotype_emb[s][c].shape[0] for c in cell_types[:i]])\n",
    "#                 i_end   = sum([cells_phenotype_emb[s][c].shape[0] for c in cell_types[:(i + 1)]])\n",
    "\n",
    "#                 j_start = sum([cells_phenotype_emb[s][c].shape[0] for c in cell_types[:j]])\n",
    "#                 j_end   = sum([cells_phenotype_emb[s][c].shape[0] for c in cell_types[:(j + 1)]])\n",
    "#     #             print(i_start, i_end)\n",
    "#     #             print(j_start, j_end)\n",
    "    \n",
    "\n",
    "#                 i_emb = cell_coordinates[s][cell_type_i]\n",
    "#                 j_emb = cell_coordinates[s][cell_type_j]\n",
    "                \n",
    "#                 src = np.mean(i_emb, axis=0).reshape(1, -1)\n",
    "#                 dst = np.mean(j_emb, axis=0).reshape(1, -1)\n",
    "                \n",
    "                src = circle_coordinates[[i_order]] * (1 - 0.15)\n",
    "                dst = circle_coordinates[[j_order]] * (1 - 0.15)\n",
    "                \n",
    "#                 print(src, dst)\n",
    "\n",
    "                verts = np.concatenate([src, np.zeros(src.shape), dst], axis=1).reshape(-1,2)\n",
    "                codes = [\n",
    "                    Path.MOVETO,\n",
    "                    Path.CURVE3,\n",
    "                    Path.MOVETO,\n",
    "                ]\n",
    "                paths = [Path([src[i], (0,0), dst[i]], codes) for i in range(src.shape[0])]\n",
    "                if edges_kwargs is None:\n",
    "                    def edges_kwargs(ct1, ct2):    \n",
    "                        if (ct1, ct2) in differential_cell_pairs_effect_size_map:\n",
    "                            p = differential_cell_pairs_effect_size_map[(ct1, ct2)]\n",
    "                        else:\n",
    "                            p = differential_cell_pairs_effect_size_map[(ct2, ct1)]\n",
    "                            \n",
    "#                         linewidth = (abs(p) - cliffs_delta_threshold) * 40 + 0.5\n",
    "                        linewidth = (abs(p) - cliffs_delta_threshold) * 60 + 0.5\n",
    "    \n",
    "#                         p = differential_cell_pairs_map[(ct1, ct2)]\n",
    "#                         linewidth = min(-np.log10(p),10)\n",
    "                        \n",
    "                        \n",
    "                        weight = mean_diff[(ct1, ct2)] # for direction (more or less)\n",
    "                        edgecolors = colors[0] if mean_diff[(ct1, ct2)] < 0 else colors[1]\n",
    "                        linestyle = \"-\" if mean_diff[(ct1, ct2)] < 0 else (0, (1,0.5))\n",
    "                        \n",
    "                        return dict(linewidths=linewidth, facecolor='none', edgecolors=edgecolors, alpha=0.7, linestyle=linestyle)\n",
    "                    \n",
    "                c = matplotlib.collections.PathCollection(paths, **edges_kwargs(cell_type_i, cell_type_j))\n",
    "                ax.add_collection(c)\n",
    "\n",
    "    #             break\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_palette = sns.color_palette(\"Spectral\", n_colors=32)\n",
    "# color_palette = sns.diverging_palette(145, 300, s=60, n=32)\n",
    "\n",
    "# innate_colors =  color_palette[:6]\n",
    "# adaptive_colors = color_palette[-11:]\n",
    "\n",
    "# innate_colors =  list(reversed(sns.color_palette(\"ch:s=-.2,r=.6\", n_colors=6))) \n",
    "# adaptive_colors = list(reversed(sns.cubehelix_palette(start=.5, rot=-.75, n_colors=11)))\n",
    "\n",
    "# innate_colors =  list(reversed(sns.color_palette(\"ch:s=-.2,r=.6\", n_colors=6)))[3:5] * 6\n",
    "# adaptive_colors = list(reversed(sns.cubehelix_palette(start=.5, rot=-.75, n_colors=11)))[6:8] * 11\n",
    "# innate_colors =  [sns.color_palette()[0]] * 6\n",
    "# adaptive_colors = [sns.color_palette()[1]] * 11\n",
    "\n",
    "innate_colors =  sns.diverging_palette(250, 30, l=75, center=\"dark\", n=18)[:6]\n",
    "adaptive_colors = list(reversed(sns.diverging_palette(250, 30, l=70, center=\"dark\", n=32)[-11:]))\n",
    "\n",
    "neutral = [(.6,.6,.6)]\n",
    "neutral_text = [(.55,.55,.55)]\n",
    "# neutral = [np.array([199,187,201]) / 255]\n",
    "# neutral_text = [np.array([199/1.5,187/1.5,201/1.5]) / 255]\n",
    "# neutral = [np.array([191,181,178]) / 255]\n",
    "# neutral = [(0.2,0.7,0.7)]\n",
    "# neutral = [(0.0,0.5,0.5)]\n",
    "color_palette_labels = color_palette_cells = neutral * 2 + innate_colors + neutral + adaptive_colors\n",
    "sns.palplot(color_palette_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette_cells = neutral * 2 + [(0.95,0.95,0.95)] * 6 + neutral + [(0.4,0.4,0.4)] * 11\n",
    "sns.palplot(color_palette_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette_labels = neutral * 2 + [contrast_colors[1]] * 6 + neutral + [contrast_colors[0]] * 11\n",
    "sns.palplot(color_palette_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette_labels = neutral * 2 + [(0.95,0.95,0.95)] * 6 + neutral + [(0.4,0.4,0.4)] * 11\n",
    "sns.palplot(color_palette_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette_labels = neutral_text * 2 + [(0.2,0.2,0.2)] * 6 + neutral_text + [(0.75,0.75,0.75)] * 11\n",
    "sns.palplot(color_palette_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference(cell_type_pair_include, edge_style, do_plot_size=True, linewidth_scaling_edges=None, linewidth_scaling_summary=None, ax=None, rename=None):\n",
    "#     colors = [\"pink\", \"gold\"]\n",
    "#     colors = [sns.color_palette(\"vlag\", as_cmap=False,n_colors=8)[-1],sns.color_palette(\"vlag\", as_cmap=False,n_colors=6)[1]]\n",
    "#     colors = [color_palette[1],color_palette[0]]\n",
    "    colors = contrast_colors\n",
    "#     colors = [(*c, 0.5) for c in colors]\n",
    "    \n",
    "    plot_cells(s, title=None, cell_colors=color_palette_cells, ax=ax)\n",
    "    plot_summary(s, colors=colors, ax=ax, cell_type_pair_include=cell_type_pair_include, linewidth_scaling=linewidth_scaling_summary)\n",
    "    plot_summary_circle_intracell(ax=ax, colors=colors, radius=1+0.16)\n",
    "#     plot_summary_circle_intracell(ax=ax, radius=1+0.17, stagger=(2,0.07))\n",
    "    plot_labels(\"T3\", ax=ax, radius=1+0.19, stagger=(2,0.05), rename=rename, cell_colors=color_palette_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_palette = sns.color_palette(\"deep\", n_colors=26)\n",
    "# sns.palplot(color_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "patchList = []\n",
    "data_key = Line2D(\n",
    "    [0], [0], marker=\"o\", color=contrast_colors[0], linestyle=\"-\", alpha=0.7,\n",
    "    linewidth=8,\n",
    "    label=\"increasing\", \n",
    "    markersize=0)\n",
    "patchList.append(data_key)\n",
    "\n",
    "data_key = Line2D(\n",
    "    [0], [0], marker=\"o\", color=contrast_colors[1], linestyle=(0, (1,0.5)), alpha=0.7,\n",
    "    linewidth=8,\n",
    "    label=f\"decreasing\", \n",
    "    markersize=0)\n",
    "patchList.append(data_key)\n",
    "\n",
    "fig, axes = plt.subplots(1,1, dpi=300, figsize=(2,2))\n",
    "ax = axes\n",
    "leg = ax.legend(handles=patchList, loc=\"upper left\", frameon=False, title=\"relative number of top correlations\", facecolor=(1,1,1,0.3), fancybox=False, edgecolor='None', borderaxespad=0.08)\n",
    "leg._legend_box.align = \"left\"\n",
    "leg.get_title().set_position((-5, 0))\n",
    "\n",
    "ax.axis(\"off\")\n",
    "ax.set_facecolor(\"green\")\n",
    "fig.savefig('../_out/figures/legend_singlecell_change.pdf', bbox_inches='tight', facecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "patchList = []\n",
    "\n",
    "data_key = Line2D(\n",
    "    [0], [0], marker=\"o\", color=(0.95,0.95,0.95), linestyle=\"-\", alpha=0.7,\n",
    "    linewidth=8,\n",
    "    label=\"adaptive\", \n",
    "    markersize=0)\n",
    "patchList.append(data_key)\n",
    "\n",
    "data_key = Line2D(\n",
    "    [0], [0], marker=\"o\", color=(0.1,0.1,0.1), linestyle=\"-\", alpha=0.7,\n",
    "    linewidth=8,\n",
    "    label=f\"innate\", \n",
    "    markersize=0)\n",
    "patchList.append(data_key)\n",
    "\n",
    "fig, axes = plt.subplots(1,1, dpi=300, figsize=(2,2))\n",
    "ax = axes\n",
    "leg = ax.legend(handles=patchList, loc=\"upper left\", frameon=False, title=\"cell types\", facecolor=(1,1,1,0.3), fancybox=False, edgecolor='None', borderaxespad=0.08)\n",
    "leg._legend_box.align = \"left\"\n",
    "leg.get_title().set_position((-5, 0))\n",
    "\n",
    "ax.axis(\"off\")\n",
    "fig.savefig('../_out/figures/legend_singlecell_cells.pdf', bbox_inches='tight', facecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "edge_style = dict(facecolor='none', edgecolors=\"grey\", alpha=0.5)\n",
    "# linewidth_scaling_edges = lambda n_edges: max(min(1 / (n_edges / 20 + 1), 1), 0.01) # gotta play with this\n",
    "# linewidth_scaling_summary = lambda p: max(3, np.log10(p) / np.log10(0.05) / 4)\n",
    "cell_type_pair_include = lambda x,y: ((x,y) in differential_cell_pairs_effect_size_map.keys()) or ((y,x) in differential_cell_pairs_effect_size_map.keys())\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(13,13), dpi=300); ax.axis(\"off\")\n",
    "plot_difference(cell_type_pair_include, edge_style, ax=ax, rename=rename)\n",
    "\n",
    "bbox = ax.get_window_extent()\n",
    "bbox_data = bbox.transformed(ax.transData.inverted())\n",
    "ax.update_datalim(bbox_data.corners())\n",
    "ax.autoscale_view()\n",
    "\n",
    "radius = 1\n",
    "a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, \n",
    "                            theta1=28, theta2=135, \n",
    "#                             theta1=-8, theta2=135, \n",
    "                            linewidth=65, \n",
    "#                             color=contrast_colors[1], \n",
    "                            color=(0.1,0.1,0.1), \n",
    "                            alpha=0.7)\n",
    "ax.add_patch(a1)\n",
    "a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, \n",
    "                            theta1=153, theta2=350, \n",
    "#                             theta1=137, theta2=350, \n",
    "                            linewidth=65,\n",
    "#                             color=contrast_colors[0], \n",
    "                            color=(0.9,0.9,0.9), \n",
    "                            alpha=0.7)\n",
    "ax.add_patch(a1)\n",
    "\n",
    "fig.savefig(path_figures / \"cell_correlations_difference.pdf\", bbox_inches=\"tight\", facecolor='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subgroup(subgroup, edge_style=None, cell_type_pair_include=None, ax=None, linewidth_scaling=None):\n",
    "    #     cell_colors = color_palette\n",
    "    intra_colors = [\"silver\" for _ in cell_type_order]\n",
    "    \n",
    "    linewidth_log = plot_edges(subgroup, ax=ax, edges_kwargs=edge_style, cell_type_pair_include=cell_type_pair_include, linewidth_scaling=linewidth_scaling)\n",
    "    \n",
    "    plot_cells(subgroup, title=None, cell_colors=color_palette_cells, ax=ax)\n",
    "    \n",
    "#     plot_circle_size(\"T3\", cell_colors=color_palette, ax=ax, radius=1+0.17, subgroup_include=lambda s: s == \"T3\")\n",
    "    plot_circle_intra_edges(subgroup, cell_colors=intra_colors, ax=ax, radius=1+0.17)\n",
    "#     plot_circle_n_edges(\"T3\", cell_colors=color_palette, ax=ax, radius=1+0.15)\n",
    "    \n",
    "    plot_labels(\"T3\", ax=ax, radius=1+0.19, stagger=(2,0.05), rename=rename, cell_colors=color_palette_labels)\n",
    "\n",
    "    return linewidth_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_edges(subgroup, ax=None, edges_kwargs=None, cell_type_pair_include=None, linewidth_scaling=None):\n",
    "    \n",
    "    # draw embeddings\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.axis(\"off\")\n",
    "  \n",
    "    linewidth_log = dict() \n",
    "    \n",
    "    # edges\n",
    "    for i_order, cell_type_i in enumerate(cell_type_order):\n",
    "        \n",
    "        for j_order, cell_type_j in enumerate(cell_type_order):\n",
    "            \n",
    "            if (cell_type_pair_include is not None) and (not cell_type_pair_include(cell_type_i, cell_type_j)):\n",
    "                continue\n",
    "                \n",
    "            i = np.argwhere(cell_types == cell_type_i).squeeze()\n",
    "            j = np.argwhere(cell_types == cell_type_j).squeeze()\n",
    "            \n",
    "            if i_order < j_order:\n",
    "#                 print(cell_type_i, cell_type_j)\n",
    "                i_start = sum([cells_phenotype[subgroup][c].shape[0] for c in cell_types[:i]])\n",
    "                i_end   = sum([cells_phenotype[subgroup][c].shape[0] for c in cell_types[:(i + 1)]])\n",
    "\n",
    "                j_start = sum([cells_phenotype[subgroup][c].shape[0] for c in cell_types[:j]])\n",
    "                j_end   = sum([cells_phenotype[subgroup][c].shape[0] for c in cell_types[:(j + 1)]])\n",
    "    #             print(i_start, i_end)\n",
    "    #             print(j_start, j_end)\n",
    "\n",
    "                mm = topk_matrices[subgroup]\n",
    "    #             print(mm.nnz)\n",
    "                m = mm[i_start:i_end, j_start:j_end] + mm[j_start:j_end,i_start:i_end].transpose()\n",
    "#                 print(m.nnz)\n",
    "                m = m[cells_phenotype_emb_idx[subgroup][cell_type_i],:][:,cells_phenotype_emb_idx[subgroup][cell_type_j]]\n",
    "                m_coo = m.nonzero()\n",
    "\n",
    "                i_emb = cell_coordinates[subgroup][cell_type_i]\n",
    "                j_emb = cell_coordinates[subgroup][cell_type_j]\n",
    "#                 print(cell_type_i, cell_type_j)\n",
    "#                 print(j_emb.shape)\n",
    "#                 print(m_coo[1].shape)\n",
    "\n",
    "                src = i_emb[m_coo[0]]\n",
    "                dst = j_emb[m_coo[1]]\n",
    "        \n",
    "#                 # sample edges\n",
    "#                 if n_max_edges is not None:\n",
    "#                     idx = np.random.choice(src.shape[0], min(src.shape[0], n_max_edges), replace=False)\n",
    "#                     src = src[idx,:]\n",
    "#                     dst = dst[idx,:]\n",
    "                \n",
    "#                 print(src.shape)\n",
    "#                 print(dst.shape)\n",
    "\n",
    "                verts = np.concatenate([src, np.zeros(src.shape), dst], axis=1).reshape(-1,2)\n",
    "                codes = [\n",
    "                    Path.MOVETO,\n",
    "                    Path.CURVE3,\n",
    "                    Path.MOVETO,\n",
    "                ]\n",
    "    #             paths = [Path([src[i], (src[i]+dst[i]) / 2 /2, dst[i]], codes) for i in range(src.shape[0])]\n",
    "                paths = [Path([src[i], (0,0), dst[i]], codes) for i in range(src.shape[0])]\n",
    "                print(cell_type_i, cell_type_j, len(paths))\n",
    "                if linewidth_scaling is None:\n",
    "                    linewidths = 0.01\n",
    "                elif isinstance(linewidth_scaling, dict):\n",
    "                    linewidths = linewidth_scaling[(cell_type_i, cell_type_j)]\n",
    "                else:\n",
    "                    linewidths = linewidth_scaling(src.shape[0])\n",
    "                linewidth_log[(cell_type_i, cell_type_j)] = linewidths\n",
    "                    \n",
    "                if edges_kwargs is None:\n",
    "                    edges_kwargs = dict(facecolor='none', edgecolors=\"grey\", alpha=0.5)\n",
    "                c = matplotlib.collections.PathCollection(paths, **edges_kwargs, linewidths=linewidths)\n",
    "#                 c = matplotlib.collections.PathCollection(paths, linewidths=0.1, facecolor='none', edgecolors=\"grey\", alpha=0.5)\n",
    "                ax.add_collection(c)\n",
    "\n",
    "    #             break\n",
    "#         break\n",
    "    print(linewidth_log)\n",
    "    return linewidth_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#     cell_colors = get_cell_colors(marker_category=marker_category, marker=marker)\n",
    "cell_colors = color_palette\n",
    "\n",
    "# edge_style = dict(facecolor='none', edgecolors=\"black\", alpha=0.1)\n",
    "# linewidth_scaling_edges = lambda n_edges: max(min(1 / (n_edges / 20 + 1), 1)**2 * 3, 0.01) # gotta play with this\n",
    "\n",
    "edge_style = dict(facecolor='none', edgecolors=\"black\", alpha=0.1)\n",
    "linewidth_scaling_edges = lambda n_edges: max(min(1 / (n_edges / 20 + 1), 1)**2 * 3, 0.025) # gotta play with this\n",
    "# linewidth_scaling_edges = lambda n_edges: 0.06 # gotta play with this\n",
    "\n",
    "cell_type_pair_include = lambda x,y: \\\n",
    "    ((x,y) in differential_cell_pairs_effect_size_map.keys()) \\\n",
    "    or ((y,x) in differential_cell_pairs_effect_size_map.keys())\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(13,13), dpi=300); ax.axis(\"off\")\n",
    "# plot_difference(cell_type_pair_include, edge_style, ax=ax)\n",
    "\n",
    "# # show all labels\n",
    "# bbox = ax.get_window_extent()\n",
    "# bbox_data = bbox.transformed(ax.transData.inverted())\n",
    "# ax.update_datalim(bbox_data.corners())\n",
    "# ax.autoscale_view()\n",
    "\n",
    "# subgroup 1\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(13,13), dpi=300); ax.axis(\"off\")\n",
    "linewidths = plot_subgroup(\n",
    "    \"T3\", cell_type_pair_include=cell_type_pair_include, edge_style=edge_style, ax=ax, linewidth_scaling=linewidth_scaling_edges)\n",
    "# display(linewidths)\n",
    "# linewidths = {a:0 for a,b in linewidths.items()}\n",
    "\n",
    "bbox = ax.get_window_extent()\n",
    "bbox_data = bbox.transformed(ax.transData.inverted())\n",
    "ax.update_datalim(bbox_data.corners())\n",
    "ax.autoscale_view()\n",
    "#     ax.set_title(f\"T3: {marker_category} - {marker_name}\")\n",
    "\n",
    "radius = 1\n",
    "a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, \n",
    "                            theta1=28, theta2=135, \n",
    "#                             theta1=-8, theta2=135, \n",
    "                            linewidth=65, \n",
    "#                             color=contrast_colors[1], \n",
    "                            color=(0.1,0.1,0.1), \n",
    "                            alpha=0.7)\n",
    "ax.add_patch(a1)\n",
    "a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, \n",
    "                            theta1=153, theta2=350, \n",
    "#                             theta1=137, theta2=350, \n",
    "                            linewidth=65,\n",
    "#                             color=contrast_colors[0], \n",
    "                            color=(0.9,0.9,0.9), \n",
    "                            alpha=0.7)\n",
    "ax.add_patch(a1)\n",
    "\n",
    "fig.savefig(path_figures / f\"cell_correlations_t3.pdf\", bbox_inches=\"tight\", facecolor='none')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# subgroup 2\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(13,13), dpi=300); ax.axis(\"off\")\n",
    "plot_subgroup(\n",
    "    \"PP\", cell_type_pair_include=cell_type_pair_include, edge_style=edge_style, ax=ax, linewidth_scaling=linewidths)\n",
    "\n",
    "bbox = ax.get_window_extent()\n",
    "bbox_data = bbox.transformed(ax.transData.inverted())\n",
    "ax.update_datalim(bbox_data.corners())\n",
    "ax.autoscale_view()\n",
    "#     ax.set_title(f\"PP: {marker_category} - {marker_name}\")\n",
    "\n",
    "\n",
    "radius = 1\n",
    "a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, \n",
    "                            theta1=28, theta2=135, \n",
    "#                             theta1=-8, theta2=135, \n",
    "                            linewidth=65, \n",
    "#                             color=contrast_colors[1], \n",
    "                            color=(0.1,0.1,0.1), \n",
    "                            alpha=0.7)\n",
    "ax.add_patch(a1)\n",
    "a1 = matplotlib.patches.Arc((0,0), radius*2, radius*2, \n",
    "                            theta1=153, theta2=350, \n",
    "#                             theta1=137, theta2=350, \n",
    "                            linewidth=65,\n",
    "#                             color=contrast_colors[0], \n",
    "                            color=(0.9,0.9,0.9), \n",
    "                            alpha=0.7)\n",
    "ax.add_patch(a1)\n",
    "\n",
    "fig.savefig(path_figures / f\"cell_correlations_pp.pdf\", bbox_inches=\"tight\", facecolor='none')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
